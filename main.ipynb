{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pypdfium2 as pdfium\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from pytesseract import image_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_images(file_path, scale=300/72):\n",
    "    pdf_file = pdfium.PdfDocument(file_path)  \n",
    "    page_indices = [i for i in range(len(pdf_file))]\n",
    "    renderer = pdf_file.render(pdfium.PdfBitmap.to_pil, page_indices = page_indices, scale = scale)\n",
    "    \n",
    "    list_final_images = [] \n",
    "    for i, image in zip(page_indices, renderer):\n",
    "        image_byte_array = BytesIO()\n",
    "        image.save(image_byte_array, format='jpeg', optimize=True)\n",
    "        image_byte_array = image_byte_array.getvalue()\n",
    "        list_final_images.append(dict({i:image_byte_array}))\n",
    "    return list_final_images\n",
    "\n",
    "def display_images(list_dict_final_images):\n",
    "    all_images = [list(data.values())[0] for data in list_dict_final_images]\n",
    "    for index, image_bytes in enumerate(all_images):\n",
    "        image = Image.open(BytesIO(image_bytes))\n",
    "        plt.figure(figsize = (image.width / 100, image.height / 100))\n",
    "        plt.title(f\"----- Page Number {index+1} -----\")\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "def extract_text_with_pytesseract(list_dict_final_images):\n",
    "    image_list = [list(data.values())[0] for data in list_dict_final_images]\n",
    "    image_content = []\n",
    "    for image_bytes in image_list:\n",
    "        image = Image.open(BytesIO(image_bytes))\n",
    "        raw_text = str(image_to_string(image))\n",
    "        image_content.append(raw_text)\n",
    "    return \"\\n\".join(image_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = './docs'\n",
    "\n",
    "pdf_to_images = []\n",
    "for filename in os.listdir(dir_path):\n",
    "    if filename.endswith('.pdf'):\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        pdf_to_images.append(convert_pdf_to_images(file_path))\n",
    "\n",
    "display_images(pdf_to_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_text = []\n",
    "for image_file in pdf_to_images:\n",
    "    images_to_text.append(extract_text_with_pytesseract(image_file))\n",
    "\n",
    "print(images_to_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = './docs'\n",
    "parser = LlamaParse(api_key=os.environ['LLAMAINDEX_API_KEY'], result_type=\"markdown\")\n",
    "\n",
    "pdf_to_text = []\n",
    "for filename in os.listdir(dir_path):\n",
    "    if filename.endswith('.pdf'):\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        pdf_to_text.append(parser.load_data(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 Q3 AMZN.pdf\n",
      "2023 Q1 AAPL.pdf\n",
      "2023 Q3 AAPL.pdf\n",
      "2022 Q3 MSFT.pdf\n",
      "2022 Q3 INTC.pdf\n",
      "2023 Q2 AAPL.pdf\n",
      "2023 Q1 AMZN.pdf\n",
      "2022 Q3 NVDA.pdf\n",
      "2023 Q3 MSFT.pdf\n",
      "2023 Q2 INTC.pdf\n",
      "2023 Q3 NVDA.pdf\n",
      "2023 Q1 INTC.pdf\n",
      "2022 Q3 AAPL.pdf\n",
      "2023 Q1 MSFT.pdf\n",
      "2023 Q3 AMZN.pdf\n",
      "2023 Q2 NVDA.pdf\n",
      "2023 Q2 MSFT.pdf\n",
      "2023 Q2 AMZN.pdf\n",
      "2023 Q1 NVDA.pdf\n",
      "2023 Q3 INTC.pdf\n"
     ]
    }
   ],
   "source": [
    "dir_path = './docs'\n",
    "for filename in os.listdir(dir_path):\n",
    "    if filename.endswith('.pdf'):\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdf_to_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "arr = [item.text for doc in pdf_to_text for item in doc]\n",
    "\n",
    "with open('data.pkl', 'wb') as file:\n",
    "    pickle.dump(arr, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1037\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('data.pkl', 'rb') as file:\n",
    "    brr = pickle.load(file)\n",
    "\n",
    "print(len(brr))\n",
    "# for str in brr:\n",
    "    # print(len(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_index\n",
    "output = pdf_to_text[0]\n",
    "if isinstance(output, list):\n",
    "    for item in output:\n",
    "        if isinstance(item, llama_index.core.schema.Document):\n",
    "            print(item.text)\n",
    "        else:\n",
    "            print(f\"Non-Document element found: {type(item)}\")\n",
    "else:\n",
    "    print(\"Unexpected structure:\", type(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 21:53:54.997540: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-11 21:53:55.228511: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-11 21:53:55.228562: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-11 21:53:55.228989: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-11 21:53:55.294148: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-11 21:53:56.564869: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import google.generativeai as genai\n",
    "\n",
    "from langchain_community.graphs.networkx_graph import NetworkxEntityGraph\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains import GraphQAChain\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available base models: ['models/chat-bison-001', 'models/text-bison-001', 'models/embedding-gecko-001', 'models/gemini-1.0-pro-latest', 'models/gemini-1.0-pro', 'models/gemini-pro', 'models/gemini-1.0-pro-001', 'models/gemini-1.0-pro-vision-latest', 'models/gemini-pro-vision', 'models/gemini-1.5-pro-latest', 'models/gemini-1.5-pro-001', 'models/gemini-1.5-pro-002', 'models/gemini-1.5-pro', 'models/gemini-1.5-pro-exp-0801', 'models/gemini-1.5-pro-exp-0827', 'models/gemini-1.5-flash-latest', 'models/gemini-1.5-flash-001', 'models/gemini-1.5-flash-001-tuning', 'models/gemini-1.5-flash', 'models/gemini-1.5-flash-exp-0827', 'models/gemini-1.5-flash-002', 'models/gemini-1.5-flash-8b', 'models/gemini-1.5-flash-8b-001', 'models/gemini-1.5-flash-8b-latest', 'models/gemini-1.5-flash-8b-exp-0827', 'models/gemini-1.5-flash-8b-exp-0924', 'models/embedding-001', 'models/text-embedding-004', 'models/aqa']\n"
     ]
    }
   ],
   "source": [
    "genai.configure(api_key='AIzaSyBlgF7cwiOYpABXpCS9_KdgnBAayBDf9gs')\n",
    "llm = GoogleGenerativeAI(model='gemini-1.5-pro', google_api_key='AIzaSyBlgF7cwiOYpABXpCS9_KdgnBAayBDf9gs')\n",
    "\n",
    "print('Available base models:', [m.name for m in genai.list_models()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "554"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Marie Curie was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\n",
    "She was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n",
    "Her husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
    "She was, in 1906, the first woman to become a professor at the University of Paris.\n",
    "\"\"\"\n",
    "\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(item.text for doc in pdf_to_text for item in doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"huggyllama/llama-7b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [Document(page_content=text)]\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdf_to_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents.base import Document\n",
    "\n",
    "def split_documents_into_chunks(documents, chunk_size=2048, overlap_size=20):\n",
    "    chunks = []\n",
    "    for document in documents:\n",
    "        for i in range(0, len(document), chunk_size - overlap_size):\n",
    "            chunk = document[i: i + chunk_size]\n",
    "            chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "docs = [item.text for doc in pdf_to_text for item in doc]\n",
    "\n",
    "# Assuming 'documents' is a list of strings\n",
    "chunks = split_documents_into_chunks(text)\n",
    "\n",
    "# Create Document objects from chunks\n",
    "documents = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    node1 = Document(page_content=chunk, metadata={\"id\": str(i)})\n",
    "    documents.append(node1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_transformer = LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_document = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    graph_document = llm_transformer.convert_to_graph_documents(documents)\n",
    "\n",
    "print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marie Curie</td>\n",
       "      <td>physicist</td>\n",
       "      <td>OCCUPATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marie Curie</td>\n",
       "      <td>chemist</td>\n",
       "      <td>OCCUPATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marie Curie</td>\n",
       "      <td>Nobel Prize</td>\n",
       "      <td>AWARDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marie Curie</td>\n",
       "      <td>Nobel Prize</td>\n",
       "      <td>AWARDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marie Curie</td>\n",
       "      <td>Nobel Prize</td>\n",
       "      <td>AWARDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Marie Curie</td>\n",
       "      <td>Pierre Curie</td>\n",
       "      <td>SPOUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pierre Curie</td>\n",
       "      <td>Nobel Prize</td>\n",
       "      <td>AWARDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Marie Curie</td>\n",
       "      <td>professor</td>\n",
       "      <td>POSITION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Marie Curie</td>\n",
       "      <td>University of Paris</td>\n",
       "      <td>WORKS_FOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          node1                node2    relation\n",
       "0   Marie Curie            physicist  OCCUPATION\n",
       "1   Marie Curie              chemist  OCCUPATION\n",
       "2   Marie Curie          Nobel Prize     AWARDED\n",
       "3   Marie Curie          Nobel Prize     AWARDED\n",
       "4   Marie Curie          Nobel Prize     AWARDED\n",
       "5   Marie Curie         Pierre Curie      SPOUSE\n",
       "6  Pierre Curie          Nobel Prize     AWARDED\n",
       "7   Marie Curie            professor    POSITION\n",
       "8   Marie Curie  University of Paris   WORKS_FOR"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['node1', 'node2', 'relation'])\n",
    "for edge in graph_document[0].relationships:\n",
    "    df = pd.concat([df, pd.DataFrame({'node1': [edge.source.id], 'node2': [edge.target.id], 'relation': [edge.type]})], ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = NetworkxEntityGraph()\n",
    "\n",
    "for node in graph_document[0].nodes:\n",
    "    graph.add_node(node.id)\n",
    "\n",
    "for edge in graph_document[0].relationships:\n",
    "    graph._graph.add_edge(edge.source.id, edge.target.id, relation=edge.type)\n",
    "\n",
    "nx.write_gml(graph._graph, 'data.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities Extracted:\n",
      "\u001b[32;1m\u001b[1;3mMarie Curie \n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3mMarie Curie OCCUPATION physicist\n",
      "Marie Curie OCCUPATION chemist\n",
      "Marie Curie AWARDED Nobel Prize\n",
      "Marie Curie SPOUSE Pierre Curie\n",
      "Marie Curie POSITION professor\n",
      "Marie Curie WORKS_FOR University of Paris\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Who is Marie Curie?',\n",
       " 'result': 'Marie Curie was a physicist and chemist, known for winning the Nobel Prize. She was a professor at the University of Paris and was married to Pierre Curie. \\n'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with get_openai_callback() as cb:\n",
    "chain = GraphQAChain.from_llm(llm=llm, graph=graph, verbose=True)\n",
    "\n",
    "question = \"\"\"Who is Marie Curie?\"\"\"\n",
    "chain.invoke(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
